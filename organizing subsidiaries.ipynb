{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "eddee80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import numpy as np\n",
    "\n",
    "# Auth\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('gspread_creds.json', scope)\n",
    "client = gspread.authorize(creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91384af3",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0e8445",
   "metadata": {},
   "source": [
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "20839b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    'TFR-500', \n",
    "    'Tenenbaum',\n",
    "    'Moodys 32',\n",
    "    'Moodys 34',\n",
    "    'IDed in HB 32', \n",
    "    'IDed in HB 34',\n",
    "    'IDed in HB GmbH'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "96e92376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFR-500 mapping\n",
    "\n",
    "org_type_mapping = {\n",
    "    'Corporation (Aktiengesellschaft)': 'AG',\n",
    "    'GmbH': 'GmbH',\n",
    "}\n",
    "link_type_mapping = {\n",
    "    'ownership': 'USO', \n",
    "    'unknown': 'USOP', \n",
    "    'Partnership': 'USC', \n",
    "    'branch': 'USO'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "206aed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenenbaum, Moodys 32, 34 mapping\n",
    "\n",
    "def assign_link_type(row):\n",
    "    if row['mentions a subsidiary']:\n",
    "        link_type = 'USO'\n",
    "    elif row['mentions stock ownership']:\n",
    "        link_type = 'USOP'\n",
    "    elif row['mentions an affiliated company']:\n",
    "        link_type = 'USC'\n",
    "    elif row['other types of agreement']:\n",
    "        link_type = 'USC'\n",
    "    elif row['is a subsidiary of a German firm']:\n",
    "        link_type = 'DEO'\n",
    "    else:\n",
    "        link_type = 'Others'\n",
    "\n",
    "    return link_type\n",
    "\n",
    "def assign_org_type(row):\n",
    "    if row['affiliated company is AG']:\n",
    "        org_type = 'AG'\n",
    "    elif row['affiliated company is GmbH']:\n",
    "        org_type = 'GmbH'\n",
    "    else:\n",
    "        org_type = 'Others'\n",
    "\n",
    "    return org_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "e0c755d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HB AG mapping\n",
    "\n",
    "def assign_link_type_HB(row):\n",
    "    if row['Grossaktion√§r is a US comp']:\n",
    "        link_type = 'USO'\n",
    "    elif row['Director attached to a US company']:\n",
    "        link_type = 'USOP'\n",
    "    elif row['Other indicators are strong']:\n",
    "        link_type = 'USOP'\n",
    "    elif row['US location linked to a director']:\n",
    "        link_type = 'USC'\n",
    "    elif row['Bond issuance in the US']:\n",
    "        link_type = 'USB'\n",
    "    else:\n",
    "        link_type = 'Others'\n",
    "\n",
    "    return link_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82f8e5",
   "metadata": {},
   "source": [
    "### TFR-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "f78d4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the sheet\n",
    "worksheet = client.open(\"tfr500_summarized\").worksheet(\"classified\")\n",
    "\n",
    "# Get all records as list of dicts\n",
    "records = worksheet.get_all_records()\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfr500 = pd.DataFrame(records)\n",
    "\n",
    "# mapping to standard types\n",
    "tfr500['org_type'] = tfr500['Type of Organization'].map(org_type_mapping).fillna(\"Others\")\n",
    "tfr500['link_type'] = tfr500['Type of Investment'].map(link_type_mapping).fillna(\"Others\")\n",
    "\n",
    "# renaming and selecting variables\n",
    "tfr500 = tfr500.rename(columns={'American Owner - Name': 'US Company', \n",
    "                                'Master German firm name': 'German subsidiary'})\n",
    "tfr500['Vol'] = \"Vol 1\" +  \", p. \" + tfr500['page'].astype(str)\n",
    "tfr500_cleaned = tfr500[['German subsidiary', 'US Company', 'Owned Through (Allied Foreign Organization)', 'link_type', 'org_type', 'Vol', 'Type of Investment', 'Type of Organization', 'Percent Owned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "da8c9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr500_cleaned.to_csv('output/tfr_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49751d",
   "metadata": {},
   "source": [
    "### Tenenbaum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "8d3f7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the sheet\n",
    "worksheet = client.open(\"Tenenbaum\").worksheet(\"Sheet1 expanded\")\n",
    "\n",
    "# Get all records as list of dicts\n",
    "records = worksheet.get_all_records()\n",
    "\n",
    "# Convert to DataFrame\n",
    "tenenbaum = pd.DataFrame(records)\n",
    "\n",
    "# The boolean columns become string after conversion, so here we convert them back to booleans\n",
    "bool_cols = ['mentions a subsidiary', \n",
    "             'mentions stock ownership',\n",
    "             'affiliated company is AG',\n",
    "             'affiliated company is GmbH',\n",
    "             'mentions an affiliated company',\n",
    "             'mentions a plant/office/branch', \n",
    "             'is a subsidiary of a German firm',\n",
    "             'other types of agreement']\n",
    "tenenbaum[bool_cols] = tenenbaum[bool_cols].apply(lambda x: x == \"TRUE\")\n",
    "\n",
    "# standardized type mapping\n",
    "tenenbaum['link_type'] = tenenbaum.apply(assign_link_type, axis=1)\n",
    "tenenbaum['org_type'] = tenenbaum.apply(assign_org_type, axis=1)\n",
    "\n",
    "tenenbaum['Vol'] = (\n",
    "    \"Vol 1\" + \n",
    "    \", p. \" + tenenbaum['page'].astype(str)\n",
    ")\n",
    "\n",
    "# renaming and selecting variables\n",
    "tenenbaum_cleaned = tenenbaum.rename(columns={'Master US firm name': 'US Company', \n",
    "                                             'Master German firm name': 'German subsidiary',\n",
    "                                             'US firm name': 'US firm (as in book)',\n",
    "                                             'affiliated German firm name': 'Affiliated German firm (as in book)',\n",
    "                                             'notes': 'Description'})\n",
    "tenenbaum_cleaned = tenenbaum_cleaned[['German subsidiary', 'US Company', 'link_type', 'org_type', 'US firm (as in book)', 'Affiliated German firm (as in book)', 'Vol', 'Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "5a9f30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenenbaum_cleaned.to_csv('output/tenenbaum_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964bd3d3",
   "metadata": {},
   "source": [
    "### Moodys 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "b783ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the sheet\n",
    "worksheet = client.open(\"Moodys 1932\").worksheet(\"reviewed-expanded\")\n",
    "\n",
    "# Get all records as list of dicts\n",
    "records = worksheet.get_all_records()\n",
    "\n",
    "# Convert to DataFrame\n",
    "moodys32 = pd.DataFrame(records)\n",
    "\n",
    "# The boolean columns become string after conversion, so here we convert them back to booleans\n",
    "bool_cols = ['mentions a subsidiary', \n",
    "             'mentions stock ownership',\n",
    "             'affiliated company is AG',\n",
    "             'affiliated company is GmbH',\n",
    "             'mentions an affiliated company',\n",
    "             'mentions a plant/office/branch', \n",
    "             'is a subsidiary of a German firm',\n",
    "             'other types of agreement']\n",
    "moodys32[bool_cols] = moodys32[bool_cols].apply(lambda x: x == \"TRUE\")\n",
    "\n",
    "# When manually validating the data, we filled the observations without German name with \"NA\". Here we replace them with empty strings\n",
    "moodys32['affiliated German firm name'] = moodys32['affiliated German firm name'].replace('NA', '')\n",
    "\n",
    "# standardized type mapping\n",
    "moodys32['link_type'] = moodys32.apply(assign_link_type, axis=1)\n",
    "moodys32['org_type'] = moodys32.apply(assign_org_type, axis=1)\n",
    "\n",
    "moodys32['Vol'] = (\n",
    "    \"Vol 1\" + \n",
    "    \", p. \" + moodys32['page'].astype(str)\n",
    ")\n",
    "\n",
    "# renaming and selecting variables\n",
    "moodys32_cleaned = moodys32.rename(columns={'Master US firm name': 'US Company', \n",
    "                                           'Master German firm name': 'German subsidiary',\n",
    "                                           'affiliated German firm name': 'Affiliated German firm (as in book)',\n",
    "                                           'US company name': 'US firm (as in book)',\n",
    "                                           'notes': 'Description'})\n",
    "moodys32_cleaned= moodys32_cleaned[['German subsidiary', 'US Company', 'link_type', 'org_type', 'US firm (as in book)', 'Affiliated German firm (as in book)', 'Vol', 'Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "f0b138ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "moodys32_cleaned.to_csv('output/moodys32_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f424e1e",
   "metadata": {},
   "source": [
    "### Moodys 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "84e6aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the sheet\n",
    "worksheet = client.open(\"Moodys 1934\").worksheet(\"reviewed-expanded\")\n",
    "\n",
    "# Get all records as list of dicts\n",
    "records = worksheet.get_all_records()\n",
    "\n",
    "# Convert to DataFrame\n",
    "moodys34 = pd.DataFrame(records)\n",
    "\n",
    "# The boolean columns become string after conversion, so here we convert them back to booleans\n",
    "bool_cols = ['mentions a subsidiary', \n",
    "             'mentions stock ownership',\n",
    "             'affiliated company is AG',\n",
    "             'affiliated company is GmbH',\n",
    "             'mentions an affiliated company',\n",
    "             'mentions a plant/office/branch', \n",
    "             'is a subsidiary of a German firm',\n",
    "             'other types of agreement']\n",
    "moodys34[bool_cols] = moodys34[bool_cols].apply(lambda x: x == \"TRUE\")\n",
    "\n",
    "# When manually validating the data, we filled the observations without German name with \"NA\". Here we replace them with empty strings\n",
    "moodys34['affiliated German firm name'] = moodys34['affiliated German firm name'].replace('NA', '')\n",
    "\n",
    "# standardized type mapping\n",
    "moodys34['link_type'] = moodys34.apply(assign_link_type, axis=1)\n",
    "moodys34['org_type'] = moodys34.apply(assign_org_type, axis=1)\n",
    "\n",
    "moodys34['Vol'] = (\n",
    "    \"Vol 1\" + \n",
    "    \", p. \" + moodys34['page'].astype(str)\n",
    ")\n",
    "\n",
    "# renaming and selecting variables\n",
    "moodys34_cleaned = moodys34.rename(columns={'Master US firm name': 'US Company', \n",
    "                                           'Master German firm name': 'German subsidiary',\n",
    "                                           'affiliated German firm name': 'Affiliated German firm (as in book)',\n",
    "                                           'US company name': 'US firm (as in book)',\n",
    "                                           'notes': 'Description'})\n",
    "moodys34_cleaned = moodys34_cleaned[['German subsidiary', 'US Company', 'link_type', 'org_type', 'US firm (as in book)', 'Affiliated German firm (as in book)', 'Vol', 'Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "76afe08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "moodys34_cleaned.to_csv('output/moodys34_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff32eebb",
   "metadata": {},
   "source": [
    "### HBAG 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "944444d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the sheet\n",
    "worksheet = client.open(\"Handbuch 1932\").worksheet(\"validated\")\n",
    "\n",
    "# Get all records as list of dicts\n",
    "records = worksheet.get_all_records()\n",
    "\n",
    "# Convert to DataFrame\n",
    "hb1932 = pd.DataFrame(records)\n",
    "\n",
    "# The boolean columns become string after conversion, so here we convert them back to booleans\n",
    "bool_cols = ['Grossaktion√§r is a US comp',\n",
    "             'Director attached to a US company', \n",
    "             'US location linked to a director',\n",
    "             'US-sounding names', \n",
    "             'Bond issuance in the US', \n",
    "             'Other indicators are strong']\n",
    "hb1932[bool_cols] = hb1932[bool_cols].apply(lambda x: x == \"TRUE\")\n",
    "\n",
    "# standardized type mapping\n",
    "hb1932['link_type'] = hb1932.apply(assign_link_type_HB, axis=1)\n",
    "hb1932 = hb1932.assign(org_type = 'AG') # all firms are AG in HB\n",
    "\n",
    "# renaming and selecting variables\n",
    "hb1932 = hb1932.rename(columns={'Master US firm name': 'US Company', \n",
    "                                'Master name': 'German subsidiary',\n",
    "                                'corrected firm name': 'Affiliated German firm (as in book)',\n",
    "                                'US parent': 'US firm (as in book)',\n",
    "                                })\n",
    "hb1932['Vol'] = (\n",
    "    \"Vol \" + hb1932['band'].astype(str) + \n",
    "    \", p. \" + hb1932['firmname_page'].astype(str)\n",
    ")\n",
    "hb1932_result = hb1932[['German subsidiary', 'US Company', 'link_type', 'org_type', 'US firm (as in book)', 'Affiliated German firm (as in book)', 'Vol', 'Grossaktion√§r is a US comp',\n",
    "                        'Director attached to a US company', 'US location linked to a director',\n",
    "                        'US-sounding names', 'Bond issuance in the US', 'Other indicators',\n",
    "                        'Other indicators are strong']]\n",
    "\n",
    "# Excluding those not validated\n",
    "hb1932_cleaned = hb1932_result[hb1932_result['link_type']!='Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "8eb8bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hb1932_cleaned.to_csv('output/hb32_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941510a",
   "metadata": {},
   "source": [
    "### HBAG 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "370b5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the sheet\n",
    "worksheet = client.open(\"Handbuch 1934\").worksheet(\"validated\")\n",
    "\n",
    "# Get all records as list of dicts\n",
    "records = worksheet.get_all_records()\n",
    "\n",
    "# Convert to DataFrame\n",
    "hb1934 = pd.DataFrame(records)\n",
    "\n",
    "# The boolean columns become string after conversion, so here we convert them back to booleans\n",
    "bool_cols = ['Grossaktion√§r is a US comp',\n",
    "             'Director attached to a US company', \n",
    "             'US location linked to a director',\n",
    "             'US-sounding names', \n",
    "             'Bond issuance in the US', \n",
    "             'Other indicators are strong']\n",
    "hb1934[bool_cols] = hb1934[bool_cols].apply(lambda x: x == \"TRUE\")\n",
    "\n",
    "# standardized type mapping\n",
    "hb1934['link_type'] = hb1934.apply(assign_link_type_HB, axis=1)\n",
    "hb1934 = hb1934.assign(org_type = 'AG')\n",
    "\n",
    "# renaming and selecting variables\n",
    "hb1934 = hb1934.rename(columns={\n",
    "    'Master US firm name': 'US Company', \n",
    "    'Master name': 'German subsidiary',\n",
    "    'corrected firm name': 'Affiliated German firm (as in book)',\n",
    "    'US parent': 'US firm (as in book)',\n",
    "})\n",
    "hb1934['band'] = hb1934['band']-90\n",
    "hb1934['Vol'] = (\n",
    "    \"Vol \" + hb1934['band'].astype(str) + \n",
    "    \", p. \" + hb1934['page'].astype(str)\n",
    ")\n",
    "hb1934_result = hb1934[['German subsidiary', 'US Company', 'link_type', 'org_type', 'US firm (as in book)', 'Affiliated German firm (as in book)', 'Vol', 'Grossaktion√§r is a US comp',\n",
    "       'Director attached to a US company', 'US location linked to a director',\n",
    "       'US-sounding names', 'Bond issuance in the US', 'Other indicators',\n",
    "       'Other indicators are strong']]\n",
    "\n",
    "# Excluding those not validated\n",
    "hb1934_cleaned = hb1934_result[hb1934_result['link_type']!='Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "70adf5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hb1934_cleaned.to_csv('output/hb34_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea4ab7",
   "metadata": {},
   "source": [
    "### HB GmbH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "96764758",
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_gmbh = pd.read_excel('input/gmbh_validated.xlsx', sheet_name='validated')\n",
    "hb_gmbh = hb_gmbh[~hb_gmbh['validated'].isin(['Z', 'ZN'])] # Z, ZN means no connection to US\n",
    "\n",
    "# dropping duplicates: some closely related US companies are matched twice to the same company. We simply keep one.\n",
    "hb_gmbh[\"is_duplicate\"] = hb_gmbh.duplicated(subset=['Master German firm name', 'Master US firm name'])\n",
    "hb_gmbh = hb_gmbh[hb_gmbh[\"is_duplicate\"] == False]\n",
    "\n",
    "# merging back to the source to access information\n",
    "hb_gmbh_full = pd.read_csv('../Handbuch_GmbH_1932/output/firms_structured.csv')\n",
    "hb_gmbh_merged = hb_gmbh.merge(hb_gmbh_full, left_on='german_name', right_on='firm_name', how='left')\n",
    "\n",
    "# standardized type mapping\n",
    "hb_gmbh_merged = hb_gmbh_merged.rename(columns={'validated': 'link_type'}).assign(org_type='GmbH')\n",
    "\n",
    "# renaming and selecting variables\n",
    "hb_gmbh_merged = hb_gmbh_merged.rename(columns={'Master US firm name': 'US Company', \n",
    "                                                'Master German firm name': 'German subsidiary',\n",
    "                                                'german_name': 'Affiliated German firm (as in book)',\n",
    "                                                'US_name': 'US firm (as in book)'})\n",
    "hb_gmbh_merged['Vol'] = (\n",
    "    \"Vol 1\" + \n",
    "    \", p. \" + hb_gmbh_merged['page'].astype(int).astype(str)\n",
    ")\n",
    "\n",
    "hb_gmbh_cleaned = hb_gmbh_merged[[\n",
    "    'German subsidiary', 'US Company', 'link_type', 'org_type', 'US firm (as in book)', \n",
    "    'Affiliated German firm (as in book)', 'other sources', 'notes', 'Vol', 'location', 'date', 'capital', 'business', 'persons', 'type'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "9381b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_gmbh_cleaned.to_csv('output/hb_gmbh_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0586d0",
   "metadata": {},
   "source": [
    "## Merging all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27c46e",
   "metadata": {},
   "source": [
    "### Subsidiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "8a164ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority = {\"USO\": 1, \"USOP\": 2, \"USC\": 3, \"USB\": 4, \"DEO\": 5, \"Others\": 6}\n",
    "\n",
    "def to_german_df(df):\n",
    "    df_german = df.copy().drop(columns='US Company')\n",
    "    df_german[\"priority\"] = df_german[\"link_type\"].map(priority)\n",
    "    df_german = (\n",
    "        df_german.loc[df_german.groupby(\"German subsidiary\")[\"priority\"].idxmin()]\n",
    "        .drop(columns=[\"priority\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    df_german = df_german[df_german['German subsidiary']!='']\n",
    "    df_german = df_german[['German subsidiary', 'link_type', 'org_type']]\n",
    "    return df_german"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "81055bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = [\n",
    "    tfr500_cleaned,\n",
    "    tenenbaum_cleaned,\n",
    "    moodys32_cleaned,\n",
    "    moodys34_cleaned,\n",
    "    hb1932_cleaned, \n",
    "    hb1934_cleaned,\n",
    "    hb_gmbh_cleaned\n",
    "]\n",
    "\n",
    "german_dfs = [to_german_df(df) for df in cleaned_dfs]\n",
    "\n",
    "german_df_keys = [\n",
    "    'TFR-500',\n",
    "    'Tenenbaum',\n",
    "    'Moodys 32',\n",
    "    'Moodys 34',\n",
    "    'IDed in HB 32',\n",
    "    'IDed in HB 34',\n",
    "    'IDed in HB GmbH'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "6ffecde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/38ww_5ts5z53mxh7j8kt4dt40000gn/T/ipykernel_11358/1570371015.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  subsidiary_merged[flag_cols] = subsidiary_merged[flag_cols].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Initialize merged with the first df\n",
    "subsidiary_merged = german_dfs[0].assign(**{german_df_keys[0]: True}).rename(columns={'link_type': f'{german_df_keys[0]}_link_type', 'org_type': f'{german_df_keys[0]}_org_type'})\n",
    "\n",
    "# Loop through the rest\n",
    "for key, df in zip(german_df_keys[1:], german_dfs[1:]):\n",
    "    subsidiary_merged = subsidiary_merged.merge(\n",
    "        df.assign(**{key: True}).rename(columns={'link_type': f'{key}_link_type', 'org_type': f'{key}_org_type'}),\n",
    "        on=\"German subsidiary\", how=\"outer\"\n",
    "    )\n",
    "\n",
    "# Fill missing flags with False\n",
    "flag_cols = [col for col in subsidiary_merged.columns if col in german_df_keys]\n",
    "subsidiary_merged[flag_cols] = subsidiary_merged[flag_cols].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "04564eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsidiary_merged.to_csv('output/all_subsidiaries.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e74f3",
   "metadata": {},
   "source": [
    "### Searching for subsidiaries in HBs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5794e80",
   "metadata": {},
   "source": [
    "#### Searching for subsidiaries in HB AG 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "7eec0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset once: those not in HB 32\n",
    "subsidiaries_not_ided_in_hb32 = subsidiary_merged[~subsidiary_merged['IDed in HB 32']].copy()\n",
    "\n",
    "# Collect all columns ending in _org_type except HB 32\n",
    "org_type_cols = [f\"{s}_org_type\" for s in sources if s != \"IDed in HB 32\"]\n",
    "\n",
    "# Find all subsidiaries with \"AG\" in any org_type column\n",
    "mask = subsidiaries_not_ided_in_hb32[org_type_cols].eq(\"AG\").any(axis=1)\n",
    "\n",
    "# Get unique list\n",
    "subsidiaries_to_search_list = sorted(subsidiaries_not_ided_in_hb32.loc[mask, \"German subsidiary\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "ff33d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hb32_searched = pd.read_excel('hb32_manual_searched.xlsx')\n",
    "subsidiaries_to_search_hb32_df = pd.DataFrame({'German subsidiary': subsidiaries_to_search_list})\n",
    "\n",
    "# importing the previously searched \n",
    "manual_searched_hb32 = pd.read_excel('manual/subsidiaries_to_search_hb32_manual.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "c5cdede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_manual_merged = subsidiaries_to_search_hb32_df.merge(manual_searched_hb32[['German subsidiary', \n",
    "                                                              'firmname',\n",
    "                                                              'band', \n",
    "                                                              'firmname_page',\n",
    "                                                              'Present in HB 32']], on='German subsidiary', how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "4e11554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_manual_merged.to_excel('manual/subsidiaries_to_search_hb32_auto.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "279c95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rows = auto_manual_merged[auto_manual_merged['Present in HB 32'].isna()]\n",
    "\n",
    "if not missing_rows.empty:\n",
    "    missing_subs = missing_rows['German subsidiary'].tolist()\n",
    "    raise ValueError(\n",
    "        f\"Column 'Present in HB 32' contains missing values for these subsidiaries: {missing_subs}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "9d7cd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After manually completing the search\n",
    "manual_searched_hb32 = pd.read_excel('manual/subsidiaries_to_search_hb32_manual.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "cea100c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HB32 = pd.read_csv('input_handbuch/HB32.csv')\n",
    "\n",
    "manual_searched_hb32_merged_hb32 = manual_searched_hb32.merge(HB32, on='firmname', how='left')\n",
    "\n",
    "unmatched_rows = manual_searched_hb32_merged_hb32[manual_searched_hb32_merged_hb32['Present in HB 32']==1 & manual_searched_hb32_merged_hb32['band_y'].isna()]\n",
    "\n",
    "if not unmatched_rows.empty:\n",
    "    unmatched_subs = unmatched_rows['German subsidiary'].tolist()\n",
    "    raise ValueError(\n",
    "        f\": Unmatched: {unmatched_subs}\"\n",
    "    )\n",
    "\n",
    "manual_searched_hb32_merged_hb32 = manual_searched_hb32[['German subsidiary', 'firmname']].merge(HB32, on='firmname', how='inner')\n",
    "manual_searched_hb32_merged_hb32['Vol'] = (\n",
    "    \"Vol \" + manual_searched_hb32_merged_hb32['band'].astype(int).astype(str) + \n",
    "    \", p. \" + manual_searched_hb32_merged_hb32['firmname_page'].astype(int).astype(str)\n",
    ")\n",
    "manual_searched_hb32_merged_hb32['org_type'] = 'AG'\n",
    "manual_searched_hb32_merged_hb32 = manual_searched_hb32_merged_hb32.rename(columns={'firmname': 'Affiliated German firm (as in book)'})\n",
    "manual_searched_hb32_merged_hb32 = manual_searched_hb32_merged_hb32[['German subsidiary', 'Affiliated German firm (as in book)', 'Vol']]\n",
    "\n",
    "hb1932_cleaned_expanded = pd.concat([hb1932_cleaned, manual_searched_hb32_merged_hb32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "6667d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hb1932_cleaned_expanded.to_csv('output/hb1932_cleaned_expanded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fecfe5",
   "metadata": {},
   "source": [
    "#### Searching for subsidiaries in HB AG 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "c1d5a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset once: those not in HB 32\n",
    "subsidiaries_not_ided_in_hb34 = subsidiary_merged[~subsidiary_merged['IDed in HB 34']].copy()\n",
    "\n",
    "# Collect all columns ending in _org_type except HB 34\n",
    "org_type_cols = [f\"{s}_org_type\" for s in sources if s != \"IDed in HB 34\"]\n",
    "\n",
    "# Find all subsidiaries with \"AG\" in any org_type column\n",
    "mask = subsidiaries_not_ided_in_hb34[org_type_cols].eq(\"AG\").any(axis=1)\n",
    "\n",
    "# Get unique list\n",
    "subsidiaries_to_search_list = sorted(subsidiaries_not_ided_in_hb34.loc[mask, \"German subsidiary\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "f6a64c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsidiaries_to_search_hb34_df = pd.DataFrame({'German subsidiary': subsidiaries_to_search_list})\n",
    "\n",
    "# importing the previously searched \n",
    "manual_searched_hb34 = pd.read_excel('manual/subsidiaries_to_search_hb34_manual.xlsx')\n",
    "# manual_searched_hb34 = pd.read_excel('hb34_manual_searched.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "87a1fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_manual_merged = subsidiaries_to_search_hb34_df.merge(manual_searched_hb34[['German subsidiary', \n",
    "                                                              'firmname',\n",
    "                                                              'band', \n",
    "                                                              'firmname_page',\n",
    "                                                              'Present in HB 34'\n",
    "                                                              ]], on='German subsidiary', how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "5b4a0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_manual_merged.to_excel('manual/subsidiaries_to_search_hb34_auto.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "438e2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rows = auto_manual_merged[auto_manual_merged['Present in HB 34'].isna()]\n",
    "\n",
    "if not missing_rows.empty:\n",
    "    missing_subs = missing_rows['German subsidiary'].tolist()\n",
    "    raise ValueError(\n",
    "        f\"Column 'Present in HB 34' contains missing values for these subsidiaries: {missing_subs}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "916b8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After manually completing the search\n",
    "manual_searched_hb34 = pd.read_excel('manual/subsidiaries_to_search_hb34_manual.xlsx')\n",
    "manual_searched_hb34['firmname'] = manual_searched_hb34['firmname'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "c45762c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HB34 = pd.read_csv('input_handbuch/HB34.csv').rename(columns={'page': 'firmname_page'})\n",
    "\n",
    "manual_searched_hb34_merged_hb34 = manual_searched_hb34.merge(HB34, on='firmname', how='left')\n",
    "\n",
    "unmatched_rows = manual_searched_hb34_merged_hb34[manual_searched_hb34_merged_hb34['Present in HB 34']==1 & manual_searched_hb34_merged_hb34['band_y'].isna()]\n",
    "\n",
    "if not unmatched_rows.empty:\n",
    "    unmatched_subs = unmatched_rows['German subsidiary'].tolist()\n",
    "    raise ValueError(\n",
    "        f\": Unmatched: {unmatched_subs}\"\n",
    "    )\n",
    "\n",
    "manual_searched_hb34_merged_hb34 = manual_searched_hb34[['German subsidiary', 'firmname']].merge(HB34, on='firmname', how='inner')\n",
    "manual_searched_hb34_merged_hb34['Vol'] = (\n",
    "    \"Vol \" + manual_searched_hb34_merged_hb34['band'].astype(int).astype(str)+ \n",
    "    \", p. \" + manual_searched_hb34_merged_hb34['firmname_page'].astype(int).astype(str)\n",
    ")\n",
    "manual_searched_hb34_merged_hb34['org_type'] = 'AG'\n",
    "manual_searched_hb34_merged_hb34 = manual_searched_hb34_merged_hb34.rename(columns={'firmname': 'Affiliated German firm (as in book)'})\n",
    "manual_searched_hb34_merged_hb34 = manual_searched_hb34_merged_hb34[['German subsidiary', 'org_type', 'Affiliated German firm (as in book)', 'Vol']]\n",
    "\n",
    "hb1934_cleaned_expanded = pd.concat([hb1934_cleaned, manual_searched_hb34_merged_hb34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "e4818ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hb1934_cleaned_expanded.to_csv('output/hb1934_cleaned_expanded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8368260",
   "metadata": {},
   "source": [
    "#### Searching for subsidiaries in HB GmbH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "b43a87f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset once: those not in HB GmbH\n",
    "subsidiaries_not_ided_in_hb_gmbh = subsidiary_merged[~subsidiary_merged['IDed in HB GmbH']].copy()\n",
    "\n",
    "# Collect all columns ending in _org_type except HB 34\n",
    "org_type_cols = [f\"{s}_org_type\" for s in sources if s != \"IDed in HB GmbH\"]\n",
    "\n",
    "# Find all subsidiaries with \"AG\" in any org_type column\n",
    "mask = subsidiaries_not_ided_in_hb_gmbh[org_type_cols].eq(\"GmbH\").any(axis=1)\n",
    "\n",
    "# Get unique list\n",
    "subsidiaries_to_search_list = sorted(subsidiaries_not_ided_in_hb_gmbh.loc[mask, \"German subsidiary\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "11205b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsidiaries_to_search_hb_gmbh_df = pd.DataFrame({'German subsidiary': subsidiaries_to_search_list})\n",
    "\n",
    "# importing the previously searched \n",
    "# manual_searched_hb_gmbh = pd.read_csv('list_gmbh/output/all_searched_in_hb_gmbh.csv')\n",
    "manual_searched_hb_gmbh = pd.read_excel('manual/subsidiaries_to_search_hb_gmbh_manual.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "a2d67733",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_manual_merged = subsidiaries_to_search_hb_gmbh_df.merge(manual_searched_hb_gmbh[['German subsidiary', \n",
    "                                                              'firm_name',\n",
    "                                                              'Present in HB GmbH']], on='German subsidiary', how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "id": "32225af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_manual_merged.to_excel('manual/subsidiaries_to_search_hb_gmbh_auto.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "d06b1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "if auto_manual_merged['Present in HB GmbH'].isna().any():\n",
    "    raise ValueError(f\"Column 'Present in HB GmbH' contains missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "16c4ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After manually completing the search\n",
    "manual_searched_hb_gmbh = pd.read_excel('manual/subsidiaries_to_search_hb_gmbh_manual.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "5e86da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HB_GmbH = pd.read_csv('input_handbuch/HB_GmbH_32.csv')[['firm_name', 'page', 'location', 'date', 'capital', 'business', 'persons', 'type']]\n",
    "HB_GmbH = HB_GmbH[HB_GmbH['firm_name'].notna()]\n",
    "\n",
    "manual_searched_hb_gmbh_merged_hb_gmbh = manual_searched_hb_gmbh.merge(HB_GmbH, on='firm_name', how='left')\n",
    "\n",
    "unmatched_rows = manual_searched_hb_gmbh_merged_hb_gmbh[manual_searched_hb_gmbh_merged_hb_gmbh['Present in HB GmbH']==1 & manual_searched_hb_gmbh_merged_hb_gmbh['location'].isna()]\n",
    "\n",
    "if not unmatched_rows.empty:\n",
    "    unmatched_subs = unmatched_rows['firm_name'].tolist()\n",
    "    raise ValueError(\n",
    "        f\": Unmatched: {unmatched_subs}\"\n",
    "    )\n",
    "\n",
    "manual_searched_hb_gmbh_merged_hb_gmbh = manual_searched_hb_gmbh.merge(HB_GmbH, on='firm_name', how='inner')\n",
    "manual_searched_hb_gmbh_merged_hb_gmbh['Vol'] = (\n",
    "    \"Vol 1\" + \n",
    "    \", p. \" + manual_searched_hb_gmbh_merged_hb_gmbh['page'].astype(int).astype(str)\n",
    ")\n",
    "manual_searched_hb_gmbh_merged_hb_gmbh['org_type'] = 'GmbH'\n",
    "manual_searched_hb_gmbh_merged_hb_gmbh = manual_searched_hb_gmbh_merged_hb_gmbh.rename(columns={'firm_name': 'Affiliated German firm (as in book)'})\n",
    "manual_searched_hb_gmbh_merged_hb_gmbh = manual_searched_hb_gmbh_merged_hb_gmbh[['German subsidiary', 'org_type', 'Affiliated German firm (as in book)', 'Vol', 'location', 'date', 'capital', 'business', 'persons', 'type']]\n",
    "\n",
    "hb_gmbh_cleaned_expanded = pd.concat([hb_gmbh_cleaned, manual_searched_hb_gmbh_merged_hb_gmbh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "6e6fab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_gmbh_cleaned_expanded.to_csv('output/hb_gmbh_cleaned_expanded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513a2aa",
   "metadata": {},
   "source": [
    "### Merging all searched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "7c720eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/38ww_5ts5z53mxh7j8kt4dt40000gn/T/ipykernel_11358/1570371015.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  subsidiary_merged[flag_cols] = subsidiary_merged[flag_cols].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Initialize merged with the first df\n",
    "subsidiary_merged = german_dfs[0].assign(**{german_df_keys[0]: True}).rename(columns={'link_type': f'{german_df_keys[0]}_link_type', 'org_type': f'{german_df_keys[0]}_org_type'})\n",
    "\n",
    "# Loop through the rest\n",
    "for key, df in zip(german_df_keys[1:], german_dfs[1:]):\n",
    "    subsidiary_merged = subsidiary_merged.merge(\n",
    "        df.assign(**{key: True}).rename(columns={'link_type': f'{key}_link_type', 'org_type': f'{key}_org_type'}),\n",
    "        on=\"German subsidiary\", how=\"outer\"\n",
    "    )\n",
    "\n",
    "# Fill missing flags with False\n",
    "flag_cols = [col for col in subsidiary_merged.columns if col in german_df_keys]\n",
    "subsidiary_merged[flag_cols] = subsidiary_merged[flag_cols].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "fd140ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_searched_df(df, source):\n",
    "    df_cleaned = df.rename(columns={'Master German firm name': 'German subsidiary'})\n",
    "    df_cleaned = df_cleaned[['German subsidiary', f'Present in {source}']]\n",
    "    df_cleaned[f'Present in {source}'] = df_cleaned[f'Present in {source}'].astype(bool)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "091bd1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_dfs = [\n",
    "    manual_searched_hb32, \n",
    "    manual_searched_hb34,\n",
    "    manual_searched_hb_gmbh\n",
    "]\n",
    "\n",
    "searched_dfs_keys = [\n",
    "    'HB 32',\n",
    "    'HB 34',\n",
    "    'HB GmbH'\n",
    "]\n",
    "\n",
    "cleaned_searched_dfs = [clean_searched_df(df, source) for df, source in zip(searched_dfs, searched_dfs_keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "f6300133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/38ww_5ts5z53mxh7j8kt4dt40000gn/T/ipykernel_11358/1570371015.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  subsidiary_merged[flag_cols] = subsidiary_merged[flag_cols].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Initialize merged with the first df\n",
    "subsidiary_merged = german_dfs[0].assign(**{german_df_keys[0]: True}).rename(columns={'link_type': f'{german_df_keys[0]}_link_type', 'org_type': f'{german_df_keys[0]}_org_type'})\n",
    "\n",
    "# Loop through the rest\n",
    "for key, df in zip(german_df_keys[1:], german_dfs[1:]):\n",
    "    subsidiary_merged = subsidiary_merged.merge(\n",
    "        df.assign(**{key: True}).rename(columns={'link_type': f'{key}_link_type', 'org_type': f'{key}_org_type'}),\n",
    "        on=\"German subsidiary\", how=\"outer\"\n",
    "    )\n",
    "\n",
    "# Fill missing flags with False\n",
    "flag_cols = [col for col in subsidiary_merged.columns if col in german_df_keys]\n",
    "subsidiary_merged[flag_cols] = subsidiary_merged[flag_cols].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "59be6f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/38ww_5ts5z53mxh7j8kt4dt40000gn/T/ipykernel_11358/3611757631.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  subsidiary_merged_searched['Present in HB 32'] = subsidiary_merged_searched['Present in HB 32'].fillna(subsidiary_merged_searched['IDed in HB 32'])\n",
      "/var/folders/44/38ww_5ts5z53mxh7j8kt4dt40000gn/T/ipykernel_11358/3611757631.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  subsidiary_merged_searched[f'Present in {key}'] = subsidiary_merged_searched[f'Present in {key}'].fillna(subsidiary_merged_searched[f'IDed in {key}'])\n",
      "/var/folders/44/38ww_5ts5z53mxh7j8kt4dt40000gn/T/ipykernel_11358/3611757631.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  subsidiary_merged_searched[f'Present in {key}'] = subsidiary_merged_searched[f'Present in {key}'].fillna(subsidiary_merged_searched[f'IDed in {key}'])\n"
     ]
    }
   ],
   "source": [
    "subsidiary_merged_searched = subsidiary_merged.merge(cleaned_searched_dfs[0], on='German subsidiary', how='left')\n",
    "subsidiary_merged_searched['Present in HB 32'] = subsidiary_merged_searched['Present in HB 32'].fillna(subsidiary_merged_searched['IDed in HB 32'])\n",
    "\n",
    "# Loop through the rest\n",
    "for key, df in zip(searched_dfs_keys[1:], cleaned_searched_dfs[1:]):\n",
    "    subsidiary_merged_searched = subsidiary_merged_searched.merge(\n",
    "        df, on=\"German subsidiary\", how=\"left\"\n",
    "    )\n",
    "    subsidiary_merged_searched[f'Present in {key}'] = subsidiary_merged_searched[f'Present in {key}'].fillna(subsidiary_merged_searched[f'IDed in {key}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "ab42a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsidiary_merged_searched.to_csv('output/all_subsidiaries_searched.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "91ac80b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\n",
    "    '1. Band 1-1648',\n",
    "    '2. Band 1649-3472',\n",
    "    '3. Band 3473-5104',\n",
    "    '4. Band 5105-6759'\n",
    "]\n",
    "\n",
    "hb32_full = pd.concat([pd.read_csv(f'input_handbuch/HB32_firm_names/firm_names_{band}.csv').assign(band=str(i+1)) for i, band in enumerate(bands)])\n",
    "hb32_full = hb32_full[['band', 'firmname_page', 'firmname']]\n",
    "hb32_full = hb32_full.rename({'band': 'vol', 'firmname_page': 'page'})\n",
    "hb32_full['firmname'] = hb32_full['firmname'].str.strip().str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "hb32_full.to_csv('input_handbuch/HB32.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "40e07e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [91, 92, 93, 94]\n",
    "\n",
    "hb34_full = pd.concat([pd.read_csv(f'input_handbuch/HB34_firm_names/firmnames_band{band}.csv').assign(band=str(i+1)) for i, band in enumerate(bands)])\n",
    "hb34_full = hb34_full[['band', 'page', 'firmname']]\n",
    "hb34_full = hb34_full.rename({'band': 'vol'})\n",
    "hb34_full['firmname'] = hb34_full['firmname'].str.strip().str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "hb34_full.to_csv('input_handbuch/HB34.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "0ae7e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_source_dict = {\n",
    "    'TFR-500': 'TFR-500',\n",
    "    'Tenenbaum': 'Tenenbaum',\n",
    "    'Moodys 32': 'Moodys 32',\n",
    "    'Moodys 34': 'Moodys 34',\n",
    "    'Present in HB 32': 'HB 32',\n",
    "    'Present in HB 34': 'HB 34',\n",
    "    'Present in HB GmbH': 'HB GmbH'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da6f981",
   "metadata": {},
   "source": [
    "### Merging parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "f30bdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_parent_df(df):\n",
    "    df_parent = df.copy().drop(columns=['German subsidiary', 'org_type'])\n",
    "    df_parent = df_parent[df_parent['US Company'].notna()]\n",
    "    df_parent[\"priority\"] = df_parent[\"link_type\"].map(priority)\n",
    "    df_parent = (\n",
    "        df_parent.loc[df_parent.groupby(\"US Company\")[\"priority\"].idxmin()]\n",
    "        .drop(columns=[\"priority\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    df_parent = df_parent[df_parent['US Company']!='']\n",
    "    df_parent = df_parent[['US Company', 'link_type']]\n",
    "    return df_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "00d745c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = [\n",
    "    tfr500_cleaned,\n",
    "    tenenbaum_cleaned,\n",
    "    moodys32_cleaned,\n",
    "    moodys34_cleaned,\n",
    "    hb1932_cleaned, \n",
    "    hb1934_cleaned,\n",
    "    hb_gmbh_cleaned\n",
    "]\n",
    "\n",
    "parent_dfs = [to_parent_df(df) for df in cleaned_dfs]\n",
    "\n",
    "parent_df_keys = [\n",
    "    'TFR-500',\n",
    "    'Tenenbaum',\n",
    "    'Moodys 32',\n",
    "    'Moodys 34',\n",
    "    'HB 32',\n",
    "    'HB 34',\n",
    "    'HB GmbH'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "97999554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/38ww_5ts5z53mxh7j8kt4dt40000gn/T/ipykernel_11358/284979574.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  parent_merged[flag_cols] = parent_merged[flag_cols].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Initialize merged with the first df\n",
    "parent_merged = parent_dfs[0].assign(**{parent_df_keys[0]: True}).rename(columns={'link_type': f'{parent_df_keys[0]}_link_type'})\n",
    "\n",
    "# Loop through the rest\n",
    "for key, df in zip(parent_df_keys[1:], parent_dfs[1:]):\n",
    "    parent_merged = parent_merged.merge(\n",
    "        df.assign(**{key: True}).rename(columns={'link_type': f'{key}_link_type'}),\n",
    "        on=\"US Company\", how=\"outer\"\n",
    "    )\n",
    "\n",
    "# Fill missing flags with False\n",
    "flag_cols = [col for col in parent_merged.columns if col in parent_df_keys]\n",
    "parent_merged[flag_cols] = parent_merged[flag_cols].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "1abe6b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_merged.to_csv('output/all_parents.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
